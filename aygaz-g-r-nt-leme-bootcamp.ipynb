{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aygaz GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme KampÄ±","metadata":{}},{"cell_type":"markdown","source":" **Projenin AmacÄ± ve KapsamÄ±**:\n\nBu proje, **gÃ¶rÃ¼ntÃ¼ iÅŸleme ve derin Ã¶ÄŸrenme** tekniklerini kullanarak Ã§eÅŸitli hayvanlarÄ± sÄ±nÄ±flandÄ±rmaya yÃ¶nelik bir model geliÅŸtirmeyi amaÃ§lamaktadÄ±r. Aygaz GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme KampÄ±'nda Ã¶ÄŸrendiÄŸimiz yÃ¶ntemleri uygulayarak, farklÄ± hayvan tÃ¼rlerini doÄŸru ÅŸekilde sÄ±nÄ±flandÄ±rabilen bir yapay zeka modelinin eÄŸitilmesi hedeflenmiÅŸtir. \n\nProje kapsamÄ±nda:\n\n* **Hayvan tÃ¼rleri**: Leopar, Dolphin, Aslan, Tilki, Moose, TavÅŸan, At, Sincap, Yarasa, ve Goril gibi 10 farklÄ± hayvan tÃ¼rÃ¼ sÄ±nÄ±flandÄ±rÄ±lmaktadÄ±r. \n\n* **Veri Seti**: Bu proje, hayvan gÃ¶rselleri iÃ§eren geniÅŸ bir veri setini kullanarak, her bir gÃ¶rseli etiketleyerek modelin doÄŸruluÄŸunu artÄ±rmayÄ± hedeflemiÅŸtir.\n\n* **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme Teknikleri**: GÃ¶rÃ¼ntÃ¼lerin parlaklÄ±k artÄ±rma, renk sabitliÄŸi uygulama gibi manipÃ¼lasyonlarla modellenin dayanÄ±klÄ±lÄ±ÄŸÄ± test edilmiÅŸtir. ","metadata":{}},{"cell_type":"markdown","source":"## **ğŸ› ï¸ Gerekli KÃ¼tÃ¼phaneler ve Ä°ÅŸlevleri:**\n* **os, shutil**: Dosya ve klasÃ¶r yÃ¶netimi iÅŸlemleri iÃ§in.\n* **cv2 (OpenCV)**: GÃ¶rÃ¼ntÃ¼ iÅŸleme ve boyutlandÄ±rma iÃ§in.\n* **numpy**: SayÄ±sal hesaplamalar ve veri manipÃ¼lasyonu iÃ§in.\n* **ImageDataGenerator**: GÃ¶rÃ¼ntÃ¼ veri artÄ±rma (augmentation) iÃ§in.\n* **train_test_split**: EÄŸitim ve test veri setlerini ayÄ±rmak iÃ§in.\n* **Model, Dense, Flatten, Dropout, BatchNormalization**: Model katmanlarÄ±nÄ± oluÅŸturmak iÃ§in Keras araÃ§larÄ±.\n* **matplotlib**: SonuÃ§larÄ± gÃ¶rselleÅŸtirmek iÃ§in.\n* **keras**: Derin Ã¶ÄŸrenme modelleme ve iÅŸlevsellik iÃ§in.\n* **models, layers**: Keras ile model ve katmanlar oluÅŸturmak iÃ§in.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\nimport random\nfrom glob import glob\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:16.858631Z","iopub.execute_input":"2024-12-22T16:09:16.859044Z","iopub.status.idle":"2024-12-22T16:09:20.188622Z","shell.execute_reply.started":"2024-12-22T16:09:16.858995Z","shell.execute_reply":"2024-12-22T16:09:20.187876Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## ğŸ“Š**Veri Setinin HazÄ±lanmasÄ±**\n10 Hayvan tÃ¼rÃ¼nÃ¼ veri setimizden seÃ§ip klasÃ¶re taÅŸÄ±yoruz.\n1. **DeÄŸiÅŸkenler ve Parametreler**:\n\n    * **image_size**: GÃ¶rÃ¼ntÃ¼lerin boyutlarÄ± (128, 128) olarak ayarlanÄ±r. ğŸ–¼ï¸\n    * **classes**: SÄ±nÄ±f isimleri (hayvan tÃ¼rleri) belirlenir. ğŸ†ğŸ¦…\n    * **images_per_class**: Her sÄ±nÄ±f iÃ§in kullanÄ±lacak gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ± (650). ğŸ–¼ï¸\n    * **source_dir**: Veri setinin bulunduÄŸu kaynak dizin. ğŸ“‚\n    * **train_dir ve val_dir**: EÄŸitim ve doÄŸrulama verilerinin depolanacaÄŸÄ± dizinler. ğŸ“\n\n\n2. **Veri HazÄ±rlama Fonksiyonu (prepare_dataset)**:\n\n    * **validation_split**: EÄŸitim ve doÄŸrulama verilerini ayÄ±ran oran (varsayÄ±lan %20). ğŸ“Š\n\n\n3. **Dizin OluÅŸturma**:\n\n    * **train_dir** ve **val_dir** iÃ§inde her sÄ±nÄ±f iÃ§in uygun alt dizinler oluÅŸturulur. ğŸ“‚\n\n\n4. **Resimlerin SeÃ§ilmesi ve KarÄ±ÅŸtÄ±rÄ±lmasÄ±**:\n\n    * Her sÄ±nÄ±ftan **650** kadar gÃ¶rÃ¼ntÃ¼ seÃ§ilir. ğŸ–¼ï¸\n    * GÃ¶rÃ¼ntÃ¼ler rastgele karÄ±ÅŸtÄ±rÄ±lÄ±r (veri Ã§eÅŸitliliÄŸi saÄŸlamak iÃ§in). ğŸ”€\n\n\n5. **EÄŸitim ve DoÄŸrulama Verisi AyÄ±rma**:\n\n    * GÃ¶rÃ¼ntÃ¼ler, validation_split oranÄ±na gÃ¶re eÄŸitim ve doÄŸrulama verilerine ayrÄ±lÄ±r. ğŸ“Š\n\n\n6. **GÃ¶rÃ¼ntÃ¼leri EÄŸitim ve DoÄŸrulama Dizine Kopyalama**:\n\n    * SeÃ§ilen eÄŸitim ve doÄŸrulama verileri uygun dizinlere kopyalanÄ±r. ğŸ“¤ğŸ“¥\n\n\n7. **BaÅŸarÄ±yla Veri Seti HazÄ±rlama**:\n\n    * Veri seti baÅŸarÄ±yla hazÄ±rlandÄ±ÄŸÄ±nda kullanÄ±cÄ±ya bilgi verilir. âœ…\n","metadata":{}},{"cell_type":"code","source":"classes = [\"leopard\", \"dolphin\", \"lion\", \"fox\", \"moose\", \"rabbit\", \"horse\", \"squirrel\", \"antelope\", \"gorilla\", \"cow\"]\nimages_per_class = 650\nsource_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\ndest_dir = \"/kaggle/FImages/FilteredImages/train\"\n\n\nos.makedirs(dest_dir, exist_ok=True)\n    \nfor class_name in classes:\n    source_path = os.path.join(source_dir, class_name)\n    dest_class_path = os.path.join(dest_dir, class_name)\n\n    os.makedirs(dest_class_path, exist_ok=True)\n        \n    images = glob(os.path.join(source_path, '*.jpg'))[:images_per_class]\n    for img in images:\n        shutil.copy(img, dest_class_path)\n           ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:20.190016Z","iopub.execute_input":"2024-12-22T16:09:20.190573Z","iopub.status.idle":"2024-12-22T16:09:38.837520Z","shell.execute_reply.started":"2024-12-22T16:09:20.190545Z","shell.execute_reply":"2024-12-22T16:09:38.836561Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## ğŸ”„**GÃ–RSELLERÄ°N YÃœKLENMESÄ° ğŸ§©**\nBu adÄ±mda, gÃ¶rselleri yÃ¼kleyip uygun ÅŸekilde etiketliyoruz, bÃ¶ylece modelin eÄŸitiminde kullanÄ±lacak hale getiriyoruz. ğŸš€\n\nğŸ“Œ Ä°ÅŸlemler:\n1. **GÃ¶rsel YÃ¼kleme**: cv2.imread() ile her bir sÄ±nÄ±fÄ±n gÃ¶rselleri okunur. ğŸ“‚\n2. **Normalizasyon**: GÃ¶rseller, modelin daha verimli Ã¶ÄŸrenmesi iÃ§in 0-1 aralÄ±ÄŸÄ±na normalleÅŸtirilir (img = img / 255.0). âš–ï¸\n3. **Etiketleme**: Her gÃ¶rsel, ait olduÄŸu sÄ±nÄ±fÄ±n adÄ± ile etiketlenir. ğŸ·ï¸\n\nğŸ“ SonuÃ§lar:\n* **X**: Ã–n iÅŸlenmiÅŸ tÃ¼m gÃ¶rseller.\n* **y**: Her gÃ¶rselin doÄŸru sÄ±nÄ±f etiketi.","metadata":{}},{"cell_type":"code","source":"def load_images(data_dir, allowed_classes):\n    images = []\n    labels = []\n    for class_name in os.listdir(data_dir):\n        if class_name not in allowed_classes:\n            continue  \n        class_path = os.path.join(data_dir, class_name)\n        for file_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, file_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                img = cv2.resize(img, (128, 128)) / 255.0\n                images.append(img)\n                labels.append(class_name)\n    return np.array(images), np.array(labels)\n\nX, y = load_images(dest_dir, classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:38.838576Z","iopub.execute_input":"2024-12-22T16:09:38.838869Z","iopub.status.idle":"2024-12-22T16:10:35.754362Z","shell.execute_reply.started":"2024-12-22T16:09:38.838843Z","shell.execute_reply":"2024-12-22T16:10:35.753339Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **ğŸ“ Veri BÃ¶lme ve KlasÃ¶r YapÄ±sÄ±nÄ±n OluÅŸturulmasÄ±:**\n1. **KlasÃ¶r YapÄ±sÄ±:**\n    * Hedef dizin **(target_dir)** ve alt dizinler **(train, val)** yoksa oluÅŸturulur.\n    * Her sÄ±nÄ±f iÃ§in de ilgili train ve val dizinleri oluÅŸturulur.\n\nğŸ“¸ Resimlerin EÄŸitim ve DoÄŸrulama KÃ¼melerine BÃ¶lÃ¼nmesi: \n\n2. **GÃ¶rselleri Listeleme ve KarÄ±ÅŸtÄ±rma:**\n\n    * Her sÄ±nÄ±f iÃ§in gÃ¶rselleri listeleyip, karÄ±ÅŸtÄ±rÄ±yoruz. Bu adÄ±m, eÄŸitim ve doÄŸrulama verilerinin rastgele seÃ§ilmesini saÄŸlar.\n\n\n3. **Veri KÃ¼mesinin BÃ¶lÃ¼nmesi:**\n    * GÃ¶rsellerin %80'i eÄŸitim, %20'si doÄŸrulama kÃ¼mesine ayrÄ±lÄ±r.\n    * **split_idx** hesaplanarak gÃ¶rseller bÃ¶lÃ¼nÃ¼r.\n\n**ğŸ“¤ GÃ¶rsellerin KopyalanmasÄ±:** \n\n4. GÃ¶rselleri Kopyalama:\n\n    * EÄŸitim ve doÄŸrulama kÃ¼melerine ayÄ±rdÄ±ktan sonra, her bir gÃ¶rsel ilgili dizine **(train_class_dir** ve **val_class_dir)** kopyalanÄ±r.\n\nğŸ”„ SonuÃ§:\nBu iÅŸlem sonunda, kaynak dizindeki gÃ¶rseller eÄŸitim ve doÄŸrulama kÃ¼melerine bÃ¶lÃ¼nerek, her bir sÄ±nÄ±f iÃ§in doÄŸru dizinlere yerleÅŸtirilmiÅŸ olur.","metadata":{}},{"cell_type":"code","source":"def split_data(source_dir, target_dir, classes, test_size=0.2):\n    \n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    \n    \n    train_dir = os.path.join(target_dir, 'train')\n    val_dir = os.path.join(target_dir, 'val')\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(val_dir, exist_ok=True)\n    \n    for class_name in classes:\n        class_path = os.path.join(source_dir, class_name)\n        \n        \n        class_train_dir = os.path.join(train_dir, class_name)\n        class_val_dir = os.path.join(val_dir, class_name)\n        os.makedirs(class_train_dir, exist_ok=True)\n        os.makedirs(class_val_dir, exist_ok=True)\n        \n        \n        images = os.listdir(class_path)\n        random.shuffle(images)\n        \n        \n        split_idx = int(len(images) * (1 - test_size))\n        train_images = images[:split_idx]\n        val_images = images[split_idx:]\n        \n        \n        for img in train_images:\n            shutil.copy(os.path.join(class_path, img), class_train_dir)\n        for img in val_images:\n            shutil.copy(os.path.join(class_path, img), class_val_dir)\n\n\nsplit_data(source_dir, dest_dir, classes, test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:10:35.756577Z","iopub.execute_input":"2024-12-22T16:10:35.756875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ”¢ Etiketlerin SayÄ±sal Hale Getirilmesi:**\n1. **LabelEncoder ile Etiket DÃ¶nÃ¼ÅŸÃ¼mÃ¼:**\n    * **LabelEncoder()** kullanÄ±larak, etiketler **(y)** sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Bu, sÄ±nÄ±flarÄ±n metin etiketlerinden (Ã¶rneÄŸin, \"leopard\", \"dolphin\") sayÄ±sal deÄŸerlere (Ã¶rneÄŸin, 0, 1, 2) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi anlamÄ±na gelir.\n    * **y_encoded = encoder.fit_transform(y)** ile her bir sÄ±nÄ±f bir sayÄ±sal etiket ile eÅŸleÅŸtirilir.\n\nğŸ”„ **Etiketlerin Kategorik Formata DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi:**\n\n2. **Kategorik Etiketler:**\n    * **to_categorical()** fonksiyonu kullanÄ±larak sayÄ±sal etiketler (0-9 arasÄ±) birer one-hot encoded (biri dÄ±ÅŸÄ±nda sÄ±fÄ±r olan vektÃ¶rler) hale getirilir.\n    * Ã–rneÄŸin, sÄ±nÄ±f 3 iÃ§in **[0, 0, 1, 0, ..., 0]** gibi bir vektÃ¶r oluÅŸturulur.\n\nğŸ“Š **Veri KÃ¼mesinin EÄŸitim ve Test KÃ¼melerine BÃ¶lÃ¼nmesi:**\n\n3. train_test_split:\n    * **train_test_split()** fonksiyonu ile gÃ¶rseller **(X)** ve etiketler **(y_categorical)** eÄŸitim ve test kÃ¼mesine ayrÄ±lÄ±r.\n    * **test_size=0.2** parametresi ile verinin %80'i eÄŸitim, %20'si test kÃ¼mesine ayrÄ±lÄ±r.\n    * **random_state=17** parametresi, iÅŸlem tekrarÄ± iÃ§in rastgelelikin sabit kalmasÄ±nÄ± saÄŸlar.\n\nğŸ”„ SonuÃ§:\nSonuÃ§ olarak, eÄŸitim iÃ§in kullanÄ±lan gÃ¶rseller **(X_train)**, test iÃ§in kullanÄ±lan gÃ¶rseller **(X_test)**, eÄŸitim etiketleri **(y_train)** ve test etiketleri **(y_test)** oluÅŸturulur. Bu adÄ±m, modelin eÄŸitim ve doÄŸrulama sÃ¼reÃ§lerinde kullanÄ±lmasÄ± iÃ§in veri kÃ¼mesinin doÄŸru ÅŸekilde bÃ¶lÃ¼nmesini saÄŸlar.","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\ny_categorical = to_categorical(y_encoded)\nX_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=17)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ› ï¸ **Veri ArtÄ±rma ile EÄŸitim ve DoÄŸrulama Veri AkÄ±ÅŸÄ± (Data Generators)**\r\n\r\nBu adÄ±mda, `ImageDataGenerator` sÄ±nÄ±fÄ± kullanÄ±larak gÃ¶rseller Ã¼zerinde Ã§eÅŸitli veri artÄ±rma teknikleri uygulanÄ±r ve modelin eÄŸitim verilerine eriÅŸim saÄŸlanÄ±r. Ä°ÅŸlem adÄ±mlarÄ± ÅŸu ÅŸekilde aÃ§Ä±klanabilir:\r\n\r\nğŸ”„ **EÄŸitim Verisi AkÄ±ÅŸÄ±:**\r\n\r\nEÄŸitim verileri Ã¼zerinde veri artÄ±rma iÅŸlemleri gerÃ§ekleÅŸtirilir. Bu, modelin daha gÃ¼Ã§lÃ¼ ve genellenebilir olmasÄ±na yardÄ±mcÄ± olur. Ã–rneÄŸin, gÃ¶rseller Ã¼zerinde dÃ¶ndÃ¼rme, kaydÄ±rma, zoom yapma, parlaklÄ±k deÄŸiÅŸimi, renk kanalÄ± kaydÄ±rmasÄ± ve yatay Ã§evrim gibi teknikler uygulanÄ±r. Bu sayede, model farklÄ± veri Ã§eÅŸitliliÄŸi ile eÄŸitilir ve daha iyi performans gÃ¶sterir.\r\n\r\nğŸ”„ **DoÄŸrulama Verisi AkÄ±ÅŸÄ±:**\r\n\r\nDoÄŸrulama verileri Ã¼zerinde de benzer veri artÄ±rma teknikleri uygulanabilir. Bu sayede, doÄŸrulama seti Ã¼zerinde de modelin genellenebilirliÄŸi artÄ±rÄ±lÄ±r.\r\n\r\nğŸš€ **SonuÃ§:**\r\n\r\nEÄŸitim ve doÄŸrulama verileri Ã¼zerinde yapÄ±lan veri artÄ±rma iÅŸlemleriyle, modelin daha fazla ve Ã§eÅŸitli veri gÃ¶rmesi saÄŸlanÄ±r. Bu, modelin genel doÄŸruluÄŸunu artÄ±rÄ±r ve aÅŸÄ±rÄ± uyum (overfitting) riskini azaltÄ±r.","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    brightness_range=[0.5, 1.5],  # ParlaklÄ±k deÄŸiÅŸimi\n    channel_shift_range=50.0,     # Renk kanalÄ± kaydÄ±rmasÄ±\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_datagen.fit(X_train)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ§  CNN Modeli ve EÄŸitimi**\nBu bÃ¶lÃ¼mde, bir **Convolutional Neural Network (CNN)** modeli oluÅŸturduk ve derledik. Model, gÃ¶rsel verileri iÅŸleyip sÄ±nÄ±flandÄ±rmak iÃ§in aÅŸaÄŸÄ±daki katmanlarÄ± iÃ§eriyor:\n\n* **Input Layer:** GÃ¶rselleri 128x128 boyutlarÄ±nda ve RGB formatÄ±nda alÄ±r.\n* **Conv2D:** GÃ¶rsellerdeki temel Ã¶zellikleri (kenar, renk vb.) Ã¶ÄŸrenmek iÃ§in filtreler uygular.\n* **MaxPooling2D:** GÃ¶rsel boyutunu kÃ¼Ã§Ã¼ltÃ¼p iÅŸlem yÃ¼kÃ¼nÃ¼ azaltÄ±r.\n* **Flatten:** 2D Ã§Ä±ktÄ±yÄ± tek boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n* **Dense Layers:** Ã–ÄŸrenilen Ã¶zellikleri daha soyut seviyelerde temsil eder ve sÄ±nÄ±flandÄ±rma yapar.\n* **Output Layer:** Her sÄ±nÄ±f iÃ§in bir tahmin yapar ve softmax fonksiyonu ile sonuÃ§larÄ± normalize eder.\n\nModelin derlenmesi iÃ§in **Adam optimizer** ve **categorical_crossentropy** kayÄ±p fonksiyonu kullanÄ±ldÄ±. Bu yapÄ±, gÃ¶rsel sÄ±nÄ±flandÄ±rma problemleri iÃ§in uygun olup, doÄŸruluk metriÄŸi ile baÅŸarÄ±sÄ±nÄ± deÄŸerlendirir.\n\neilmiÅŸtir.\r\n\r\nğŸ”„ **Veri ArtÄ±rma ve EÄŸitim Veri AkÄ±ÅŸÄ±:**\r\n\r\n- **Veri ArtÄ±rma (Data Augmentation):** GÃ¶rseller Ã¼zerinde dÃ¶ndÃ¼rme, yatay kaydÄ±rma, ve yatay Ã§evrim gibi tekniklerle veri artÄ±rma yapÄ±lÄ±r. Bu, modelin daha fazla veri ile eÄŸitilmesine olanak saÄŸlar ve modelin genellenebilirliÄŸini artÄ±rÄ±r.\r\n  \r\n- **EÄŸitim ve Test JeneratÃ¶rleri:** EÄŸitim verileri **train_generator** ile, test verileri ise **test_generator** ile iÅŸlenir. Bu jeneratÃ¶rler, her seferinde belirli sayÄ±da Ã¶rnek (32) ile modelin eÄŸitilmesini saÄŸlar.\r\n\r\nğŸš€ **SonuÃ§:**\r\n\r\nModel, eÄŸitim verileri Ã¼zerinde veri artÄ±rma iÅŸlemleriyle eÄŸitilir ve test verileriyle doÄŸrulama yapÄ±lÄ±r. Bu sÃ¼reÃ§, modelin genellenebilirliÄŸini artÄ±rarak daha saÄŸlam sonuÃ§lar elde edilmesini saÄŸlar.","metadata":{}},{"cell_type":"code","source":"model_cnn = models.Sequential([\n    layers.Input(shape=(128, 128, 3)),  \n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),  # DÃ¼zleÅŸtirme katmanÄ±\n    layers.Dense(128, activation='relu'),\n    layers.Dense(len(classes), activation='softmax')  \n])\n\n\nmodel_cnn.compile(\n    optimizer='adam',  \n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\n\n# EÄŸitim ve doÄŸrulama jeneratÃ¶rleri\ntrain_generator = datagen.flow(X_train, y_train, batch_size=32)\ntest_generator = datagen.flow(X_test, y_test, batch_size=32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“ˆ**Modelin EÄŸitimi ve Parametre AyarlarÄ±**\n\nBu adÄ±mda, modelimizi eÄŸitmek iÃ§in gerekli parametreler ayarlandÄ± ve eÄŸitim sÃ¼reci baÅŸlatÄ±ldÄ±.\n* **steps_per_epoch:** EÄŸitim verisetindeki toplam Ã¶rnek sayÄ±sÄ± (X_train) ile batch size (32) bÃ¶lÃ¼nerek bir epoch'ta kaÃ§ adÄ±m yapÄ±lacaÄŸÄ± hesaplanÄ±r. Bu, modelin her epoch sÄ±rasÄ±nda kaÃ§ kere eÄŸitim verisi ile gÃ¼ncellenmesi gerektiÄŸini belirler.\n\n* **validation_steps:** Test verisetindeki toplam Ã¶rnek sayÄ±sÄ± (X_test) ile batch size (32) bÃ¶lÃ¼nerek doÄŸrulama adÄ±mlarÄ±nÄ±n sayÄ±sÄ± belirlenir.\n\nModelin eÄŸitimi fit() fonksiyonu ile baÅŸlatÄ±ldÄ±:\n\n* **train_generator:** EÄŸitim verilerini yÃ¼kleyen ve iÅŸleyecek olan jeneratÃ¶r.\n* **validation_generator:** DoÄŸrulama verilerini yÃ¼kleyen jeneratÃ¶r.\n* **epochs:** Modelin 25 epoch boyunca eÄŸitileceÄŸi belirtilmiÅŸ.\nEÄŸitim sÄ±rasÄ±nda her epoch'ta modelin doÄŸruluk ve kayÄ±p deÄŸerleri izlenir.","metadata":{}},{"cell_type":"code","source":"steps_per_epoch = len(X_train) // 32 \nvalidation_steps = len(X_test) // 32 \n\n\nhistory = model_cnn.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=50,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ“ŠEÄŸitim SonuÃ§larÄ±nÄ±n GÃ¶rselleÅŸtirilmesi**\r\n\r\nBu adÄ±mda, modelin eÄŸitim ve doÄŸrulama doÄŸruluÄŸu ile kayÄ±p deÄŸerlerini gÃ¶rselleÅŸtirdik. EÄŸitim sÃ¼recinin nasÄ±l ilerlediÄŸini deÄŸerlendirmek iÃ§in doÄŸruluk ve kayÄ±p eÄŸrilerini Ã§izdik. \r\n\r\n- **DoÄŸruluk EÄŸrisi**: EÄŸitim ve doÄŸrulama doÄŸruluÄŸu arasÄ±ndaki farkÄ± gÃ¶steriyor. Modelin doÄŸruluÄŸunun nasÄ±l arttÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebilirsiniz.\r\n- **KayÄ±p EÄŸrisi**: EÄŸitim ve doÄŸrulama kayÄ±plarÄ±nÄ± gÃ¶sterir. EÄŸitim sÄ±rasÄ±nda modelin kaybÄ±nÄ±n nasÄ±l azaldÄ±ÄŸÄ±nÄ± ve doÄŸrulama kaybÄ±nÄ±n durumunu inceleyebilirsiniz.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Loss')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ–¼ï¸GÃ¶rsellerin ManipÃ¼le Edilmesi ve Test SonuÃ§larÄ±nÄ±n DeÄŸerlendirilmesi**\r\n\r\nBu adÄ±mda gÃ¶rseller Ã¼zerinde manipÃ¼lasyon yaparak modelin performansÄ±nÄ± deÄŸerlendirdik:\r\n\r\n- **Kontrast ArtÄ±rma**: GÃ¶rsellerin kontrastÄ± artÄ±rÄ±larak daha belirgin hale getirildi. ğŸ¨\r\n- **DÃ¶ndÃ¼rme**: GÃ¶rseller saat yÃ¶nÃ¼nde 90 derece dÃ¶ndÃ¼rÃ¼ldÃ¼. ğŸ”„\r\n- **ManipÃ¼le EdilmiÅŸ GÃ¶rsellerin Testi**: GÃ¶rsellerde yapÄ±lan bu deÄŸiÅŸiklikler modelin doÄŸruluÄŸunu nasÄ±l etkilediÄŸini gÃ¶rmek iÃ§in test setinde model deÄŸerlendirildi. ğŸ“Š\r\n\r\nğŸ“Œ **AmaÃ§**: Modelin manipÃ¼le edilmiÅŸ gÃ¶rseller Ã¼zerindeki dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± ve performansÄ±nÄ± analiz etmek.","metadata":{}},{"cell_type":"code","source":"def manipulate_images_v2(images):\n    manipulated_images = []\n    for img in images:\n        manipulated = cv2.convertScaleAbs(img, alpha=2.0, beta=0)  # Kontrast artÄ±rma\n        manipulated = cv2.rotate(manipulated, cv2.ROTATE_90_CLOCKWISE)  # DÃ¶ndÃ¼rme\n        manipulated_images.append(manipulated)\n    return np.array(manipulated_images)\n\n\nX_test_manipulated_v2 = manipulate_images_v2(X_test)\n\n\nmanipulated_loss_v2, manipulated_accuracy_v2 = model_cnn.evaluate(X_test_manipulated_v2, y_test)\nprint(f\"ManipÃ¼le EdilmiÅŸ Test DoÄŸruluÄŸu (Kontrast + DÃ¶ndÃ¼rme): {manipulated_accuracy_v2 * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ¨Renk SabitliÄŸi UygulamasÄ± ve Model PerformansÄ±**\r\n\r\nBu adÄ±mda manipÃ¼le edilmiÅŸ gÃ¶rsellere renk sabitliÄŸi uygulayarak modelin performansÄ±nÄ± deÄŸerlendirdik:\r\n\r\n- **Renk SabitliÄŸi**: GÃ¶rsellerin renk dengesi ayarlandÄ±, her renk kanalÄ±ndaki ortalama deÄŸerlere gÃ¶re Ã¶lÃ§eklendirme yapÄ±ldÄ±. ğŸŒˆ\r\n- **AmaÃ§**: ManipÃ¼lasyon sonrasÄ± renk bozulmalarÄ±nÄ± dÃ¼zelterek modelin doÄŸruluÄŸunu artÄ±rmak. ğŸ”§\r\n- **SonuÃ§larÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±**: Renk sabitliÄŸi uygulanmÄ±ÅŸ test seti ile model performansÄ± yeniden Ã¶lÃ§Ã¼ldÃ¼. ğŸ“ˆ\r\n\r\nğŸ“Œ **SonuÃ§**: Bu adÄ±m, manipÃ¼lasyondan etkilenen gÃ¶rseller Ã¼zerinde renk sabitliÄŸinin etkisini analiz etmeyi amaÃ§lar.","metadata":{}},{"cell_type":"code","source":"def apply_color_correction(image):\n    avg_b, avg_g, avg_r = cv2.mean(image)[:3]\n    scale_b = 1.0 / (avg_b + 1e-5)\n    scale_g = 1.0 / (avg_g + 1e-5)\n    scale_r = 1.0 / (avg_r + 1e-5)\n    corrected_image = image * np.array([scale_b, scale_g, scale_r])\n    corrected_image = np.clip(corrected_image, 0, 255).astype(np.uint8)\n    return corrected_image\n\n\nX_test_corrected_v2 = np.array([apply_color_correction(img) for img in X_test_manipulated_v2])\n\n\ncorrected_loss_v2, corrected_accuracy_v2 = model_cnn.evaluate(X_test_corrected_v2, y_test)\nprint(f\"Renk SabitliÄŸi UygulanmÄ±ÅŸ Test DoÄŸruluÄŸu (ManipÃ¼le EdilmiÅŸ): {corrected_accuracy_v2 * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ğŸ“ŠModel DoÄŸruluk SonuÃ§larÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±**\r\n\r\nBu aÅŸamada, modelin farklÄ± veri kÃ¼meleri Ã¼zerindeki performansÄ± karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±:\r\n\r\n1. **Orijinal Test Seti**  \r\n   - Model, hiÃ§bir manipÃ¼lasyon yapÄ±lmamÄ±ÅŸ test seti Ã¼zerinde deÄŸerlendirildi.  \r\n   - **AmaÃ§**: Modelin temel doÄŸruluÄŸunu Ã¶lÃ§mek. âœ…  \r\n   - **SonuÃ§**: Orijinal test seti doÄŸruluÄŸu: **5.40%**\r\n\r\n2. **ManipÃ¼le EdilmiÅŸ Test Seti (Kontrast + DÃ¶ndÃ¼rme)**  \r\n   - GÃ¶rseller Ã¼zerinde kontrast artÄ±rma ve dÃ¶ndÃ¼rme iÅŸlemleri uygulandÄ±.  \r\n   - **AmaÃ§**: Modelin veri manipÃ¼lasyonlarÄ±na karÅŸÄ± dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§mek. ğŸ”„  \r\n   - **SonuÃ§**: ManipÃ¼le edilmiÅŸ test seti doÄŸruluÄŸu: **5.01%**\r\n\r\n3. **Renk SabitliÄŸi UygulanmÄ±ÅŸ Test Seti**  \r\n   - ManipÃ¼le edilmiÅŸ gÃ¶rsellere renk sabitliÄŸi uygulandÄ±.  \r\n   - **AmaÃ§**: ManipÃ¼lasyon sonrasÄ± gÃ¶rsellerin renk dengesi dÃ¼zeltilerek model doÄŸruluÄŸunu artÄ±rmak. ğŸŒˆ  \r\n   - **SonuÃ§**: Renk sabitliÄŸi uygulanmÄ±ÅŸ test seti doÄŸruluÄŸu: **7.28%**\r\n\r\nğŸ“Œ **Nihai SonuÃ§lar**:  \r\n- **Orijinal** ve **manipÃ¼le edilmiÅŸ** test setleri arasÄ±nda ufak bir doÄŸruluk kaybÄ± gÃ¶zlemlendi.  \r\n- **Renk sabitliÄŸi** uygulandÄ±ÄŸÄ±nda, doÄŸruluk belirgin ÅŸekilde artÄ±rÄ±ldÄ±.  \r\nBu sonuÃ§lar, modelin manipÃ¼lasyonlara duyarlÄ± olduÄŸunu ancak renk dÃ¼zenlemeleri ile performansÄ±nÄ±n iyileÅŸtirilebileceÄŸini gÃ¶steriyor.","metadata":{}},{"cell_type":"code","source":"\nloss, test_accuracy = model_cnn.evaluate(X_test, y_test)\nprint(f\"Orijinal Test Seti DoÄŸruluÄŸu: {test_accuracy * 100:.2f}%\")\n\n\nmanipulated_loss_v2, manipulated_accuracy_v2 = model_cnn.evaluate(X_test_manipulated_v2, y_test)\nprint(f\"ManipÃ¼le EdilmiÅŸ Test DoÄŸruluÄŸu (Kontrast + DÃ¶ndÃ¼rme): {manipulated_accuracy_v2 * 100:.2f}%\")\n\n\ncorrected_loss_v2, corrected_accuracy_v2 = model_cnn.evaluate(X_test_corrected_v2, y_test)\nprint(f\"Renk SabitliÄŸi UygulanmÄ±ÅŸ Test DoÄŸruluÄŸu (ManipÃ¼le EdilmiÅŸ): {corrected_accuracy_v2 * 100:.2f}%\")\n\n\nprint(\"\\nSonuÃ§lar:\")\nprint(f\"Orijinal Test Seti DoÄŸruluÄŸu: {test_accuracy * 100:.2f}%\")\nprint(f\"ManipÃ¼le EdilmiÅŸ Test Seti DoÄŸruluÄŸu (Kontrast + DÃ¶ndÃ¼rme): {manipulated_accuracy_v2 * 100:.2f}%\")\nprint(f\"Renk SabitliÄŸi UygulanmÄ±ÅŸ Test Seti (ManipÃ¼le EdilmiÅŸ): {corrected_accuracy_v2 * 100:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}