{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aygaz Görüntü İşleme Kampı","metadata":{}},{"cell_type":"markdown","source":" **Projenin Amacı ve Kapsamı**:\n\nBu proje, **görüntü işleme ve derin öğrenme** tekniklerini kullanarak çeşitli hayvanları sınıflandırmaya yönelik bir model geliştirmeyi amaçlamaktadır. Aygaz Görüntü İşleme Kampı'nda öğrendiğimiz yöntemleri uygulayarak, farklı hayvan türlerini doğru şekilde sınıflandırabilen bir yapay zeka modelinin eğitilmesi hedeflenmiştir. \n\nProje kapsamında:\n\n* **Hayvan türleri**: Leopar, Dolphin, Aslan, Tilki, Moose, Tavşan, At, Sincap, Yarasa, ve Goril gibi 10 farklı hayvan türü sınıflandırılmaktadır. \n\n* **Veri Seti**: Bu proje, hayvan görselleri içeren geniş bir veri setini kullanarak, her bir görseli etiketleyerek modelin doğruluğunu artırmayı hedeflemiştir.\n\n* **Görüntü İşleme Teknikleri**: Görüntülerin parlaklık artırma, renk sabitliği uygulama gibi manipülasyonlarla modellenin dayanıklılığı test edilmiştir. ","metadata":{}},{"cell_type":"markdown","source":"## **🛠️ Gerekli Kütüphaneler ve İşlevleri:**\n* **os, shutil**: Dosya ve klasör yönetimi işlemleri için.\n* **cv2 (OpenCV)**: Görüntü işleme ve boyutlandırma için.\n* **numpy**: Sayısal hesaplamalar ve veri manipülasyonu için.\n* **ImageDataGenerator**: Görüntü veri artırma (augmentation) için.\n* **train_test_split**: Eğitim ve test veri setlerini ayırmak için.\n* **Model, Dense, Flatten, Dropout, BatchNormalization**: Model katmanlarını oluşturmak için Keras araçları.\n* **matplotlib**: Sonuçları görselleştirmek için.\n* **keras**: Derin öğrenme modelleme ve işlevsellik için.\n* **models, layers**: Keras ile model ve katmanlar oluşturmak için.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\nimport random\nfrom glob import glob\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:16.858631Z","iopub.execute_input":"2024-12-22T16:09:16.859044Z","iopub.status.idle":"2024-12-22T16:09:20.188622Z","shell.execute_reply.started":"2024-12-22T16:09:16.858995Z","shell.execute_reply":"2024-12-22T16:09:20.187876Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 📊**Veri Setinin Hazılanması**\n10 Hayvan türünü veri setimizden seçip klasöre taşıyoruz.\n1. **Değişkenler ve Parametreler**:\n\n    * **image_size**: Görüntülerin boyutları (128, 128) olarak ayarlanır. 🖼️\n    * **classes**: Sınıf isimleri (hayvan türleri) belirlenir. 🐆🦅\n    * **images_per_class**: Her sınıf için kullanılacak görüntü sayısı (650). 🖼️\n    * **source_dir**: Veri setinin bulunduğu kaynak dizin. 📂\n    * **train_dir ve val_dir**: Eğitim ve doğrulama verilerinin depolanacağı dizinler. 📁\n\n\n2. **Veri Hazırlama Fonksiyonu (prepare_dataset)**:\n\n    * **validation_split**: Eğitim ve doğrulama verilerini ayıran oran (varsayılan %20). 📊\n\n\n3. **Dizin Oluşturma**:\n\n    * **train_dir** ve **val_dir** içinde her sınıf için uygun alt dizinler oluşturulur. 📂\n\n\n4. **Resimlerin Seçilmesi ve Karıştırılması**:\n\n    * Her sınıftan **650** kadar görüntü seçilir. 🖼️\n    * Görüntüler rastgele karıştırılır (veri çeşitliliği sağlamak için). 🔀\n\n\n5. **Eğitim ve Doğrulama Verisi Ayırma**:\n\n    * Görüntüler, validation_split oranına göre eğitim ve doğrulama verilerine ayrılır. 📊\n\n\n6. **Görüntüleri Eğitim ve Doğrulama Dizine Kopyalama**:\n\n    * Seçilen eğitim ve doğrulama verileri uygun dizinlere kopyalanır. 📤📥\n\n\n7. **Başarıyla Veri Seti Hazırlama**:\n\n    * Veri seti başarıyla hazırlandığında kullanıcıya bilgi verilir. ✅\n","metadata":{}},{"cell_type":"code","source":"classes = [\"leopard\", \"dolphin\", \"lion\", \"fox\", \"moose\", \"rabbit\", \"horse\", \"squirrel\", \"antelope\", \"gorilla\", \"cow\"]\nimages_per_class = 650\nsource_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\ndest_dir = \"/kaggle/FImages/FilteredImages/train\"\n\n\nos.makedirs(dest_dir, exist_ok=True)\n    \nfor class_name in classes:\n    source_path = os.path.join(source_dir, class_name)\n    dest_class_path = os.path.join(dest_dir, class_name)\n\n    os.makedirs(dest_class_path, exist_ok=True)\n        \n    images = glob(os.path.join(source_path, '*.jpg'))[:images_per_class]\n    for img in images:\n        shutil.copy(img, dest_class_path)\n           ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:20.190016Z","iopub.execute_input":"2024-12-22T16:09:20.190573Z","iopub.status.idle":"2024-12-22T16:09:38.837520Z","shell.execute_reply.started":"2024-12-22T16:09:20.190545Z","shell.execute_reply":"2024-12-22T16:09:38.836561Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 🔄**GÖRSELLERİN YÜKLENMESİ 🧩**\nBu adımda, görselleri yükleyip uygun şekilde etiketliyoruz, böylece modelin eğitiminde kullanılacak hale getiriyoruz. 🚀\n\n📌 İşlemler:\n1. **Görsel Yükleme**: cv2.imread() ile her bir sınıfın görselleri okunur. 📂\n2. **Normalizasyon**: Görseller, modelin daha verimli öğrenmesi için 0-1 aralığına normalleştirilir (img = img / 255.0). ⚖️\n3. **Etiketleme**: Her görsel, ait olduğu sınıfın adı ile etiketlenir. 🏷️\n\n📍 Sonuçlar:\n* **X**: Ön işlenmiş tüm görseller.\n* **y**: Her görselin doğru sınıf etiketi.","metadata":{}},{"cell_type":"code","source":"def load_images(data_dir, allowed_classes):\n    images = []\n    labels = []\n    for class_name in os.listdir(data_dir):\n        if class_name not in allowed_classes:\n            continue  \n        class_path = os.path.join(data_dir, class_name)\n        for file_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, file_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                img = cv2.resize(img, (128, 128)) / 255.0\n                images.append(img)\n                labels.append(class_name)\n    return np.array(images), np.array(labels)\n\nX, y = load_images(dest_dir, classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:38.838576Z","iopub.execute_input":"2024-12-22T16:09:38.838869Z","iopub.status.idle":"2024-12-22T16:10:35.754362Z","shell.execute_reply.started":"2024-12-22T16:09:38.838843Z","shell.execute_reply":"2024-12-22T16:10:35.753339Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## **📁 Veri Bölme ve Klasör Yapısının Oluşturulması:**\n1. **Klasör Yapısı:**\n    * Hedef dizin **(target_dir)** ve alt dizinler **(train, val)** yoksa oluşturulur.\n    * Her sınıf için de ilgili train ve val dizinleri oluşturulur.\n\n📸 Resimlerin Eğitim ve Doğrulama Kümelerine Bölünmesi: \n\n2. **Görselleri Listeleme ve Karıştırma:**\n\n    * Her sınıf için görselleri listeleyip, karıştırıyoruz. Bu adım, eğitim ve doğrulama verilerinin rastgele seçilmesini sağlar.\n\n\n3. **Veri Kümesinin Bölünmesi:**\n    * Görsellerin %80'i eğitim, %20'si doğrulama kümesine ayrılır.\n    * **split_idx** hesaplanarak görseller bölünür.\n\n**📤 Görsellerin Kopyalanması:** \n\n4. Görselleri Kopyalama:\n\n    * Eğitim ve doğrulama kümelerine ayırdıktan sonra, her bir görsel ilgili dizine **(train_class_dir** ve **val_class_dir)** kopyalanır.\n\n🔄 Sonuç:\nBu işlem sonunda, kaynak dizindeki görseller eğitim ve doğrulama kümelerine bölünerek, her bir sınıf için doğru dizinlere yerleştirilmiş olur.","metadata":{}},{"cell_type":"code","source":"def split_data(source_dir, target_dir, classes, test_size=0.2):\n    \n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    \n    \n    train_dir = os.path.join(target_dir, 'train')\n    val_dir = os.path.join(target_dir, 'val')\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(val_dir, exist_ok=True)\n    \n    for class_name in classes:\n        class_path = os.path.join(source_dir, class_name)\n        \n        \n        class_train_dir = os.path.join(train_dir, class_name)\n        class_val_dir = os.path.join(val_dir, class_name)\n        os.makedirs(class_train_dir, exist_ok=True)\n        os.makedirs(class_val_dir, exist_ok=True)\n        \n        \n        images = os.listdir(class_path)\n        random.shuffle(images)\n        \n        \n        split_idx = int(len(images) * (1 - test_size))\n        train_images = images[:split_idx]\n        val_images = images[split_idx:]\n        \n        \n        for img in train_images:\n            shutil.copy(os.path.join(class_path, img), class_train_dir)\n        for img in val_images:\n            shutil.copy(os.path.join(class_path, img), class_val_dir)\n\n\nsplit_data(source_dir, dest_dir, classes, test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:10:35.756577Z","iopub.execute_input":"2024-12-22T16:10:35.756875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **🔢 Etiketlerin Sayısal Hale Getirilmesi:**\n1. **LabelEncoder ile Etiket Dönüşümü:**\n    * **LabelEncoder()** kullanılarak, etiketler **(y)** sayısal değerlere dönüştürülür. Bu, sınıfların metin etiketlerinden (örneğin, \"leopard\", \"dolphin\") sayısal değerlere (örneğin, 0, 1, 2) dönüştürülmesi anlamına gelir.\n    * **y_encoded = encoder.fit_transform(y)** ile her bir sınıf bir sayısal etiket ile eşleştirilir.\n\n🔄 **Etiketlerin Kategorik Formata Dönüştürülmesi:**\n\n2. **Kategorik Etiketler:**\n    * **to_categorical()** fonksiyonu kullanılarak sayısal etiketler (0-9 arası) birer one-hot encoded (biri dışında sıfır olan vektörler) hale getirilir.\n    * Örneğin, sınıf 3 için **[0, 0, 1, 0, ..., 0]** gibi bir vektör oluşturulur.\n\n📊 **Veri Kümesinin Eğitim ve Test Kümelerine Bölünmesi:**\n\n3. train_test_split:\n    * **train_test_split()** fonksiyonu ile görseller **(X)** ve etiketler **(y_categorical)** eğitim ve test kümesine ayrılır.\n    * **test_size=0.2** parametresi ile verinin %80'i eğitim, %20'si test kümesine ayrılır.\n    * **random_state=17** parametresi, işlem tekrarı için rastgelelikin sabit kalmasını sağlar.\n\n🔄 Sonuç:\nSonuç olarak, eğitim için kullanılan görseller **(X_train)**, test için kullanılan görseller **(X_test)**, eğitim etiketleri **(y_train)** ve test etiketleri **(y_test)** oluşturulur. Bu adım, modelin eğitim ve doğrulama süreçlerinde kullanılması için veri kümesinin doğru şekilde bölünmesini sağlar.","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\ny_categorical = to_categorical(y_encoded)\nX_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=17)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🛠️ **Veri Artırma ile Eğitim ve Doğrulama Veri Akışı (Data Generators)**\r\n\r\nBu adımda, `ImageDataGenerator` sınıfı kullanılarak görseller üzerinde çeşitli veri artırma teknikleri uygulanır ve modelin eğitim verilerine erişim sağlanır. İşlem adımları şu şekilde açıklanabilir:\r\n\r\n🔄 **Eğitim Verisi Akışı:**\r\n\r\nEğitim verileri üzerinde veri artırma işlemleri gerçekleştirilir. Bu, modelin daha güçlü ve genellenebilir olmasına yardımcı olur. Örneğin, görseller üzerinde döndürme, kaydırma, zoom yapma, parlaklık değişimi, renk kanalı kaydırması ve yatay çevrim gibi teknikler uygulanır. Bu sayede, model farklı veri çeşitliliği ile eğitilir ve daha iyi performans gösterir.\r\n\r\n🔄 **Doğrulama Verisi Akışı:**\r\n\r\nDoğrulama verileri üzerinde de benzer veri artırma teknikleri uygulanabilir. Bu sayede, doğrulama seti üzerinde de modelin genellenebilirliği artırılır.\r\n\r\n🚀 **Sonuç:**\r\n\r\nEğitim ve doğrulama verileri üzerinde yapılan veri artırma işlemleriyle, modelin daha fazla ve çeşitli veri görmesi sağlanır. Bu, modelin genel doğruluğunu artırır ve aşırı uyum (overfitting) riskini azaltır.","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    brightness_range=[0.5, 1.5],  # Parlaklık değişimi\n    channel_shift_range=50.0,     # Renk kanalı kaydırması\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_datagen.fit(X_train)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **🧠 CNN Modeli ve Eğitimi**\nBu bölümde, bir **Convolutional Neural Network (CNN)** modeli oluşturduk ve derledik. Model, görsel verileri işleyip sınıflandırmak için aşağıdaki katmanları içeriyor:\n\n* **Input Layer:** Görselleri 128x128 boyutlarında ve RGB formatında alır.\n* **Conv2D:** Görsellerdeki temel özellikleri (kenar, renk vb.) öğrenmek için filtreler uygular.\n* **MaxPooling2D:** Görsel boyutunu küçültüp işlem yükünü azaltır.\n* **Flatten:** 2D çıktıyı tek boyutlu vektöre dönüştürür.\n* **Dense Layers:** Öğrenilen özellikleri daha soyut seviyelerde temsil eder ve sınıflandırma yapar.\n* **Output Layer:** Her sınıf için bir tahmin yapar ve softmax fonksiyonu ile sonuçları normalize eder.\n\nModelin derlenmesi için **Adam optimizer** ve **categorical_crossentropy** kayıp fonksiyonu kullanıldı. Bu yapı, görsel sınıflandırma problemleri için uygun olup, doğruluk metriği ile başarısını değerlendirir.\n\neilmiştir.\r\n\r\n🔄 **Veri Artırma ve Eğitim Veri Akışı:**\r\n\r\n- **Veri Artırma (Data Augmentation):** Görseller üzerinde döndürme, yatay kaydırma, ve yatay çevrim gibi tekniklerle veri artırma yapılır. Bu, modelin daha fazla veri ile eğitilmesine olanak sağlar ve modelin genellenebilirliğini artırır.\r\n  \r\n- **Eğitim ve Test Jeneratörleri:** Eğitim verileri **train_generator** ile, test verileri ise **test_generator** ile işlenir. Bu jeneratörler, her seferinde belirli sayıda örnek (32) ile modelin eğitilmesini sağlar.\r\n\r\n🚀 **Sonuç:**\r\n\r\nModel, eğitim verileri üzerinde veri artırma işlemleriyle eğitilir ve test verileriyle doğrulama yapılır. Bu süreç, modelin genellenebilirliğini artırarak daha sağlam sonuçlar elde edilmesini sağlar.","metadata":{}},{"cell_type":"code","source":"model_cnn = models.Sequential([\n    layers.Input(shape=(128, 128, 3)),  \n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),  # Düzleştirme katmanı\n    layers.Dense(128, activation='relu'),\n    layers.Dense(len(classes), activation='softmax')  \n])\n\n\nmodel_cnn.compile(\n    optimizer='adam',  \n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\n\n# Eğitim ve doğrulama jeneratörleri\ntrain_generator = datagen.flow(X_train, y_train, batch_size=32)\ntest_generator = datagen.flow(X_test, y_test, batch_size=32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📈**Modelin Eğitimi ve Parametre Ayarları**\n\nBu adımda, modelimizi eğitmek için gerekli parametreler ayarlandı ve eğitim süreci başlatıldı.\n* **steps_per_epoch:** Eğitim verisetindeki toplam örnek sayısı (X_train) ile batch size (32) bölünerek bir epoch'ta kaç adım yapılacağı hesaplanır. Bu, modelin her epoch sırasında kaç kere eğitim verisi ile güncellenmesi gerektiğini belirler.\n\n* **validation_steps:** Test verisetindeki toplam örnek sayısı (X_test) ile batch size (32) bölünerek doğrulama adımlarının sayısı belirlenir.\n\nModelin eğitimi fit() fonksiyonu ile başlatıldı:\n\n* **train_generator:** Eğitim verilerini yükleyen ve işleyecek olan jeneratör.\n* **validation_generator:** Doğrulama verilerini yükleyen jeneratör.\n* **epochs:** Modelin 25 epoch boyunca eğitileceği belirtilmiş.\nEğitim sırasında her epoch'ta modelin doğruluk ve kayıp değerleri izlenir.","metadata":{}},{"cell_type":"code","source":"steps_per_epoch = len(X_train) // 32 \nvalidation_steps = len(X_test) // 32 \n\n\nhistory = model_cnn.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=50,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **📊Eğitim Sonuçlarının Görselleştirilmesi**\r\n\r\nBu adımda, modelin eğitim ve doğrulama doğruluğu ile kayıp değerlerini görselleştirdik. Eğitim sürecinin nasıl ilerlediğini değerlendirmek için doğruluk ve kayıp eğrilerini çizdik. \r\n\r\n- **Doğruluk Eğrisi**: Eğitim ve doğrulama doğruluğu arasındaki farkı gösteriyor. Modelin doğruluğunun nasıl arttığını gözlemleyebilirsiniz.\r\n- **Kayıp Eğrisi**: Eğitim ve doğrulama kayıplarını gösterir. Eğitim sırasında modelin kaybının nasıl azaldığını ve doğrulama kaybının durumunu inceleyebilirsiniz.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Loss')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **🖼️Görsellerin Manipüle Edilmesi ve Test Sonuçlarının Değerlendirilmesi**\r\n\r\nBu adımda görseller üzerinde manipülasyon yaparak modelin performansını değerlendirdik:\r\n\r\n- **Kontrast Artırma**: Görsellerin kontrastı artırılarak daha belirgin hale getirildi. 🎨\r\n- **Döndürme**: Görseller saat yönünde 90 derece döndürüldü. 🔄\r\n- **Manipüle Edilmiş Görsellerin Testi**: Görsellerde yapılan bu değişiklikler modelin doğruluğunu nasıl etkilediğini görmek için test setinde model değerlendirildi. 📊\r\n\r\n📌 **Amaç**: Modelin manipüle edilmiş görseller üzerindeki dayanıklılığını ve performansını analiz etmek.","metadata":{}},{"cell_type":"code","source":"def manipulate_images_v2(images):\n    manipulated_images = []\n    for img in images:\n        manipulated = cv2.convertScaleAbs(img, alpha=2.0, beta=0)  # Kontrast artırma\n        manipulated = cv2.rotate(manipulated, cv2.ROTATE_90_CLOCKWISE)  # Döndürme\n        manipulated_images.append(manipulated)\n    return np.array(manipulated_images)\n\n\nX_test_manipulated_v2 = manipulate_images_v2(X_test)\n\n\nmanipulated_loss_v2, manipulated_accuracy_v2 = model_cnn.evaluate(X_test_manipulated_v2, y_test)\nprint(f\"Manipüle Edilmiş Test Doğruluğu (Kontrast + Döndürme): {manipulated_accuracy_v2 * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **🎨Renk Sabitliği Uygulaması ve Model Performansı**\r\n\r\nBu adımda manipüle edilmiş görsellere renk sabitliği uygulayarak modelin performansını değerlendirdik:\r\n\r\n- **Renk Sabitliği**: Görsellerin renk dengesi ayarlandı, her renk kanalındaki ortalama değerlere göre ölçeklendirme yapıldı. 🌈\r\n- **Amaç**: Manipülasyon sonrası renk bozulmalarını düzelterek modelin doğruluğunu artırmak. 🔧\r\n- **Sonuçların Karşılaştırılması**: Renk sabitliği uygulanmış test seti ile model performansı yeniden ölçüldü. 📈\r\n\r\n📌 **Sonuç**: Bu adım, manipülasyondan etkilenen görseller üzerinde renk sabitliğinin etkisini analiz etmeyi amaçlar.","metadata":{}},{"cell_type":"code","source":"def apply_color_correction(image):\n    avg_b, avg_g, avg_r = cv2.mean(image)[:3]\n    scale_b = 1.0 / (avg_b + 1e-5)\n    scale_g = 1.0 / (avg_g + 1e-5)\n    scale_r = 1.0 / (avg_r + 1e-5)\n    corrected_image = image * np.array([scale_b, scale_g, scale_r])\n    corrected_image = np.clip(corrected_image, 0, 255).astype(np.uint8)\n    return corrected_image\n\n\nX_test_corrected_v2 = np.array([apply_color_correction(img) for img in X_test_manipulated_v2])\n\n\ncorrected_loss_v2, corrected_accuracy_v2 = model_cnn.evaluate(X_test_corrected_v2, y_test)\nprint(f\"Renk Sabitliği Uygulanmış Test Doğruluğu (Manipüle Edilmiş): {corrected_accuracy_v2 * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **📊Model Doğruluk Sonuçlarının Karşılaştırılması**\r\n\r\nBu aşamada, modelin farklı veri kümeleri üzerindeki performansı karşılaştırıldı:\r\n\r\n1. **Orijinal Test Seti**  \r\n   - Model, hiçbir manipülasyon yapılmamış test seti üzerinde değerlendirildi.  \r\n   - **Amaç**: Modelin temel doğruluğunu ölçmek. ✅  \r\n   - **Sonuç**: Orijinal test seti doğruluğu: **5.40%**\r\n\r\n2. **Manipüle Edilmiş Test Seti (Kontrast + Döndürme)**  \r\n   - Görseller üzerinde kontrast artırma ve döndürme işlemleri uygulandı.  \r\n   - **Amaç**: Modelin veri manipülasyonlarına karşı dayanıklılığını ölçmek. 🔄  \r\n   - **Sonuç**: Manipüle edilmiş test seti doğruluğu: **5.01%**\r\n\r\n3. **Renk Sabitliği Uygulanmış Test Seti**  \r\n   - Manipüle edilmiş görsellere renk sabitliği uygulandı.  \r\n   - **Amaç**: Manipülasyon sonrası görsellerin renk dengesi düzeltilerek model doğruluğunu artırmak. 🌈  \r\n   - **Sonuç**: Renk sabitliği uygulanmış test seti doğruluğu: **7.28%**\r\n\r\n📌 **Nihai Sonuçlar**:  \r\n- **Orijinal** ve **manipüle edilmiş** test setleri arasında ufak bir doğruluk kaybı gözlemlendi.  \r\n- **Renk sabitliği** uygulandığında, doğruluk belirgin şekilde artırıldı.  \r\nBu sonuçlar, modelin manipülasyonlara duyarlı olduğunu ancak renk düzenlemeleri ile performansının iyileştirilebileceğini gösteriyor.","metadata":{}},{"cell_type":"code","source":"\nloss, test_accuracy = model_cnn.evaluate(X_test, y_test)\nprint(f\"Orijinal Test Seti Doğruluğu: {test_accuracy * 100:.2f}%\")\n\n\nmanipulated_loss_v2, manipulated_accuracy_v2 = model_cnn.evaluate(X_test_manipulated_v2, y_test)\nprint(f\"Manipüle Edilmiş Test Doğruluğu (Kontrast + Döndürme): {manipulated_accuracy_v2 * 100:.2f}%\")\n\n\ncorrected_loss_v2, corrected_accuracy_v2 = model_cnn.evaluate(X_test_corrected_v2, y_test)\nprint(f\"Renk Sabitliği Uygulanmış Test Doğruluğu (Manipüle Edilmiş): {corrected_accuracy_v2 * 100:.2f}%\")\n\n\nprint(\"\\nSonuçlar:\")\nprint(f\"Orijinal Test Seti Doğruluğu: {test_accuracy * 100:.2f}%\")\nprint(f\"Manipüle Edilmiş Test Seti Doğruluğu (Kontrast + Döndürme): {manipulated_accuracy_v2 * 100:.2f}%\")\nprint(f\"Renk Sabitliği Uygulanmış Test Seti (Manipüle Edilmiş): {corrected_accuracy_v2 * 100:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}